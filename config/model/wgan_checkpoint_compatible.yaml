# WGAN model configuration compatible with existing checkpoints
_target_: models.wgan.WGAN

# Model architecture parameters - fixed to match existing checkpoint
latent_dim: 100  # DO NOT CHANGE - must match checkpoint
img_channels: 1
img_size: 64  # Will be overridden by actual data size
hidden_dim: 64   # DO NOT CHANGE - must match checkpoint

# Training parameters
batch_size: 32
lr: 0.0001
n_critic: 5  # Train critic 5 times per generator step
lambda_gp: 10  # Gradient penalty coefficient
seed: -1
train_set_size: -1  # -1 means use all available data
n_compute_steps: 2_500_000
# n_epochs will be computed dynamically as int(n_compute_steps / train_set_size)

# Note: This config is designed to be compatible with existing checkpoints
# For parameter-constrained training from scratch, use wgan_paramconstrained.yaml
